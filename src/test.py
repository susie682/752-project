from pyspark.sql import SparkSession
from pyspark.ml.recommendation import ALS
from pyspark.ml.evaluation import RegressionEvaluator
from pyspark.sql.functions import col, explode, row_number
from pyspark.sql.window import Window
import time

# åˆå§‹åŒ– SparkSession
spark = SparkSession.builder \
    .appName("RunALSFromMappedData") \
    .config("spark.hadoop.fs.defaultFS", "hdfs://localhost:8020") \
    .config("spark.executor.memory", "4g") \
    .config("spark.driver.memory", "4g") \
    .getOrCreate()

# å¼€å§‹è®¡æ—¶
x = 1000
# è¯»å–ç”¨æˆ·å’Œå•†å“æ˜ å°„è¡¨
user_ids = spark.read.option("header", "false").csv("hdfs://localhost:8020/user/ecommerce_project/mapping_user_id") \
    .toDF("user_id", "userIndex")
item_ids = spark.read.option("header", "false").csv("hdfs://localhost:8020/user/ecommerce_project/mapping_asin_id") \
    .toDF("asin", "itemIndex")

# è¯»å–è¯„åˆ†æ•°æ®ï¼ˆä½¿ç”¨å°æ•°æ®é›†ï¼‰
ratings = spark.read.option("header", "false").csv(f"hdfs://localhost:8020/user/ecommerce_project/cleaned_data_{x}") \
    .toDF("user_id", "asin", "rating")
ratings = ratings.withColumn("rating", col("rating").cast("float"))

# ç¼“å­˜å¹¶è¾“å‡ºè°ƒè¯•ä¿¡æ¯
ratings.cache()



# åŠ å…¥ç´¢å¼•ï¼Œæ„é€  ALS è¾“å…¥æ ¼å¼
indexed = ratings.join(user_ids, on="user_id", how="inner") \
                 .join(item_ids, on="asin", how="inner") \
                 .select(col("userIndex").cast("int"), col("itemIndex").cast("int"), col("rating"))
start_time = time.time()
# æ‹†åˆ†è®­ç»ƒ / æµ‹è¯•é›†

training, test = indexed.randomSplit([0.8, 0.2], seed=42)
# æ„å»ºå¹¶è®­ç»ƒ ALS æ¨¡å‹
als = ALS(
    maxIter=15,
    regParam=0.05,
    rank=20,
    userCol="userIndex",
    itemCol="itemIndex",
    ratingCol="rating",
    coldStartStrategy="drop"
)
model = als.fit(training)

# é¢„æµ‹è¯„åˆ†ï¼šè‹¥ test æ— ç»“æœåˆ™å›é€€ training
predictions = model.transform(test)
if predictions.rdd.isEmpty():
    print("â— No predictions generated. Using training set instead.")
    predictions = model.transform(training)



# è¯„ä¼° RMSE
evaluator = RegressionEvaluator(
    metricName="rmse",
    labelCol="rating",
    predictionCol="prediction"
)
rmse = evaluator.evaluate(predictions)
print(f"Data Count =  {x}")
print(f"ğŸ“‰ALS  RMSE = {rmse:.3f}")


# æ¨èæµç¨‹è®¡æ—¶ç»“æŸ
end_time = time.time()
print(f"â±ï¸ ALS recommendation time costï¼š{end_time - start_time:.2f} Seconds")

print(f"æ•°æ®æ€»é‡: {ratings.count()}")


# åœæ­¢ Spark
spark.stop()